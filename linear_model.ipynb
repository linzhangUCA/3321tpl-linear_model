{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uU4TDl3qnNoU"
      },
      "source": [
        "# Linear Model Used Car Price Predictor \n",
        "**Due: Wednesday, 09/27/2022, 2:15 PM**\n",
        "\n",
        "Welcome to your second assignment! You will train a linear model to predict used cars' prices based on their ages.\n",
        "\n",
        "\n",
        "Exercises:\n",
        "1. $\\color{violet}{\\textbf{(10\\%) Data Visualization}}$\n",
        "2. $\\color{violet}{\\textbf{(10\\%) Create a Linear Model}}$\n",
        "3. $\\color{violet}{\\textbf{(10\\%) Calculate Mean Square Error}}$\n",
        "4. $\\color{violet}{\\textbf{(60\\%) Gradient Descent Optimization}}$\n",
        "5. $\\color{violet}{\\textbf{(10\\%) Test Model with New Data}}$\n",
        "\n",
        "\n",
        "**Instructions:**\n",
        "- Write your code only between the $\\color{green}{\\textbf{\\small \\#\\#\\# START CODE HERE \\#\\#\\#}}$ and $\\color{green}{\\textbf{\\small \\#\\#\\# END CODE HERE \\#\\#\\#}}$ commented lines. $\\color{red}{\\textbf{Do not modify code out of the designated area.}}$\n",
        "- Reference answers are provided after a certain coding blocks. Be aware if your answer is different from the reference..\n",
        "- Avoid using for-loops and while-loops, unless you are explicitly told to do so.\n",
        "\n",
        "**After this assignment you will:**\n",
        "\n",
        "- Be able to train a neural network model with the simplest form: single-in, single-out linear function.\n",
        "    - Initialize weight and bias parameters.\n",
        "    - Use a loss function to evaluate the model's performance.\n",
        "    - Optimize the weight and bias parameters using gradient descent algorithm.\n",
        "- Get more used to vectorization using NumPy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9O8WWMZnNoa"
      },
      "source": [
        "## 1 - Load the Data ##\n",
        "The objective is to predict a car's price given its age. And we need data to build such a predictor (model). First, let's load the data and plot a figure to roughly observe the relationship between ages and prices of the cars.\n",
        "#### $\\color{violet}{\\textbf{(10\\%) Exercise 1: Data Visualization}}$\n",
        "**Note: Do not connect datapoints with lines.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoobNZRqnNoZ"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and preprocess the data (year, price)\n",
        "X_train = np.load(\"years_train.npy\") / 10  # rescale to per decade\n",
        "y_train = np.load(\"prices_train.npy\") / 1e4  # rescale to per $10,000\n",
        "print(f\"There are {X_train.shape[0]} samples in the data.\")\n",
        "\n",
        "# Visualize the data\n",
        "plt.xlabel(\"Age (decades)\")\n",
        "plt.ylabel(\"Price ($10,000)\")\n",
        "### START CODE HERE ### (≈ 1 line of code)\n",
        " \n",
        "### END CODE HERE ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwI1Oek2Lm3g"
      },
      "source": [
        "## 2 - Create a Model\n",
        "Create a linear model: $\\hat{y} = wx + b$ govern by the weight parameter, $w$ and bias parameter, $b$. The independent variable, $x$ indicates the age of a car, and the dependent variable $\\hat{y}$ is the predicted price of the car.\n",
        "#### $\\color{violet}{\\textbf{(10\\%) Exercise 2: Create a Linear Model}}$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yskxxiiJLm3g"
      },
      "outputs": [],
      "source": [
        "def forward(w, b, x):\n",
        "    \"\"\"\n",
        "    Linear model function\n",
        "        Args:\n",
        "            w: weight parameter, a scalar\n",
        "            b: bias parameter, a scalar\n",
        "            x: independent variable, a 1-D numpy array\n",
        "        Returns:\n",
        "            yhat: dependent variable, a 1-D numpy array\n",
        "    \"\"\"\n",
        "    ### START CODE HERE ### (≈ 1 line of code)\n",
        "    yhat = None\n",
        "    ### END CODE HERE ###\n",
        "    return yhat\n",
        "\n",
        "# Sanity check\n",
        "print(f\"The model's output from 4 input values: {forward(2, -3, np.linspace(-0.2, 0.2, 4))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_cGkT_DnNoe"
      },
      "source": [
        "**Expected Output**:\n",
        ">\n",
        "```console\n",
        "The model's output from 4 input values: [-3.4        -3.13333333 -2.86666667 -2.6       ]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62kon6iDLm3h"
      },
      "source": [
        "To initialize the model, we need to initialize $w$ and $b$. It is very common in deep learning to initialize the parameters to small values. And we can visualize the initial model after that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYBCNzkQLm3i"
      },
      "outputs": [],
      "source": [
        "np.random.seed(3321)\n",
        "# Initialize model\n",
        "w = np.random.normal(loc=0, scale=1e-4)\n",
        "b = np.random.normal(loc=0, scale=1e-4)\n",
        "print(f\"w0={w}, b0={b}\")\n",
        "# Visualize the model\n",
        "plt.xlabel(\"Age (decades)\")\n",
        "plt.ylabel(\"Price ($10,000)\")\n",
        "plt.plot(X_train, y_train, 'o')\n",
        "plt.plot([0, 5], forward(w, b, np.array([0, 5])), 'r')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6JQy67bLm3i"
      },
      "source": [
        "## 3 - Evaluate the Model\n",
        "We need a criteria to evaluate the performance of the model. Mean square error function: $\\mathcal{L}(\\hat{y}, y) = \\frac{1}{2M}\\Sigma_{i=1}^M(\\hat{y}_i - y_i)^2$ is usually applied to calculate the averaged error between the model predicted values and data originated values. $M$ is the total number of datapoints, $\\hat{y}$ is the model predicted value, $y$ is the data originate value (true value), $i$ is the index of a certain datapoint.\n",
        "\n",
        "#### $\\color{violet}{\\textbf{(10\\%) Exercise 3: Calculate Mean Square Error}}$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouqlM7NXLm3j"
      },
      "outputs": [],
      "source": [
        "def mse_loss(pred, true):\n",
        "    \"\"\"\n",
        "    Mean square error (MSE) function\n",
        "        Args:\n",
        "            pred: model predicted value, a 1-D numpy array\n",
        "            true: true value, a 1-D numpy array\n",
        "        Returns:\n",
        "            loss_value: averaged MSE error, a scalar\n",
        "    \"\"\"\n",
        "    ### START CODE HERE ### (≈ 1 line of code)\n",
        "    loss_value = None\n",
        "    ### END CODE HERE ###\n",
        "    return loss_value\n",
        "\n",
        "# Sanity check\n",
        "print(f\"Model's MSE loss: {mse_loss(pred=forward(w, b, X_train), true=y_train)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yDIakRnLm3j"
      },
      "source": [
        "**Expected Output**:\n",
        ">\n",
        "```console\n",
        "Model's MSE loss: 2.1660192668556335\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVqdjG9pnNof"
      },
      "source": [
        "## 4 - Gradient Descent Optimization\n",
        "We need to calculate the gradient of the loss function $\\mathcal{L}$ (derivatives with respect to $w$ and $b$). The purpose of doing so is to determine directions that increment $w$ and $b$ to reduce the MSE loss of the model. The gradient of the loss function can be computed as:\n",
        "\n",
        "$\\frac{\\partial \\mathcal{L}}{\\partial w} = \\frac{1}{M}\\Sigma_{i=1}^M(\\hat{y}_i - y_i)x_i$\n",
        "\n",
        "$\\frac{\\partial \\mathcal{L}}{\\partial b} = \\frac{1}{M}\\Sigma_{i=1}^M(\\hat{y}_i - y_i)$\n",
        "\n",
        "To optimize $w$ and $b$, we need to perform gradient descent algorithm:\n",
        "\n",
        "$\\textbf{Initialize } w, b$\n",
        "\n",
        "$\\text{\\textbf{Repeat} until converge } \\{$\n",
        "\n",
        "&nbsp; &nbsp; &nbsp; &nbsp; $\\text{compute } \\frac{\\partial \\mathcal{L}}{\\partial w} \\text{, and } \\frac{\\partial \\mathcal{L}}{\\partial b}$\n",
        "\n",
        "&nbsp; &nbsp; &nbsp; &nbsp; $w := w - \\alpha \\frac{\\partial \\mathcal{L}}{\\partial w}$\n",
        "\n",
        "&nbsp; &nbsp; &nbsp; &nbsp; $b := b - \\alpha \\frac{\\partial \\mathcal{L}}{\\partial b}$\n",
        "\n",
        "$\\}$\n",
        "\n",
        "where $\\alpha$ is the learning rate (step size).\n",
        "\n",
        "#### $\\color{violet}{\\textbf{(60\\%) Exercise 4: Gradient Descent Optimization}}$\n",
        "Please complete the following two tasks in the next code block.\n",
        "1. Define a function to compute gradient ($\\frac{\\partial \\mathcal{L}}{\\partial w}$ and $\\frac{\\partial \\mathcal{L}}{\\partial b}$)\n",
        "2. Use a iterative loop to update $w$ and $b$. **Please store model loss in each iteration to a list/array.**\n",
        "\n",
        "You can replace `None`s with appropriate variables or operations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNk1R3Z5Lm3j"
      },
      "outputs": [],
      "source": [
        "def grad(x, y, yhat):\n",
        "    \"\"\"\n",
        "    Compute gradient of loss function\n",
        "        Args:\n",
        "            x: independent variables, a 1-D numpy array\n",
        "            y: true value, a 1-D numpy array\n",
        "            yhat: model predicted value, a 1-D numpy array\n",
        "        Returns:\n",
        "            dw: dL/dw, a scalar\n",
        "            db: dL/db, a scalar\n",
        "    \"\"\"\n",
        "    ### START CODE HERE ### (≈ 2 lines of code)\n",
        "    dw = None  # dL/dw\n",
        "    db = None  # dL/db\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return dw, db\n",
        "\n",
        "# Optimization\n",
        "### START CODE HERE ### (≈ 7 lines of code)\n",
        "num_iters = None\n",
        "learning_rate = None\n",
        "losses = []  # storage for loss at each iteration\n",
        "for i in range(num_iters):\n",
        "    pred = None\n",
        "    dw, db = None\n",
        "    w = None\n",
        "    b = None\n",
        "    loss = None\n",
        "    print(f\"loss @ {i+1} iteration: {loss}\")\n",
        "    # print(f\"w = {w}, b = {b}\")  # uncomment this line if need to debug\n",
        "    losses.append(loss)\n",
        "### END CODE HERE ###\n",
        "\n",
        "# To visualize changing of the loss\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"MSE loss\")\n",
        "plt.plot(losses)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWk5WnrdLm3k"
      },
      "source": [
        "## 5 - Test the Model\n",
        "The model was trained in the previous steps. Now, let's test the model with a new set of data.\n",
        "\n",
        "#### $\\color{violet}{\\textbf{(10\\%) Exercise 5: Test Model with New Data}}$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGUiJJQ9Lm3k"
      },
      "outputs": [],
      "source": [
        "# Load test data\n",
        "X_test = np.load(\"years_test.npy\") / 10  # rescale to per decade\n",
        "y_test = np.load(\"prices_test.npy\") / 1e4  # rescale to per $10,000\n",
        "print(f\"There are {X_test.shape[0]} samples in the test dataset.\")\n",
        "\n",
        "# You'll need to calculate mse loss of the model on the test data\n",
        "### START CODE HERE ### (≈ 2 lines of code)\n",
        "pred_test = None\n",
        "loss_test = None\n",
        "### END CODE HERE ###\n",
        "print(f\"MSE prediction error on test data: {loss_test}\")\n",
        "\n",
        "# To visualize the model for how it fits to the test data\n",
        "plt.xlabel(\"Age (decades)\")\n",
        "plt.ylabel(\"Price ($10,000)\")\n",
        "plt.plot(X_test, y_test, 'o')\n",
        "plt.plot([0, 5], forward(w, b, np.array([0, 5])), 'r')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You may observe that the model did somehow catch the relationship between ages and prices of the cars. However, it does not make sense to predict negative price for the cars older than 3 decades. We'll investigate approaches to avoid this in the future.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Congratulations! You have finished this assignment!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "coursera": {
      "course_slug": "neural-networks-deep-learning",
      "graded_item_id": "XaIWT",
      "launcher_item_id": "zAgPl"
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit ('3.10.6')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "d270a79710bdef277cbe1980c659a200a6519333aa892b0e4ae637e197c06188"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
